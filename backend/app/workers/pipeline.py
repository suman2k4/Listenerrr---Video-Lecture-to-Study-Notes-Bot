import json
import time
import uuid
from pathlib import Path
from typing import Any, Dict

from celery import Celery
from fpdf import FPDF

from app.config import settings
from app.database import SessionLocal
from app.models import Job, JobStage, JobStatus

celery_app = Celery(
    "listenerrr",
    broker=settings.celery_broker_url,
    backend=settings.celery_result_backend,
)
celery_app.conf.task_always_eager = settings.celery_task_always_eager

STAGE_SEQUENCE = [
    JobStage.extracting_audio,
    JobStage.transcribing,
    JobStage.ocr,
    JobStage.aligning,
    JobStage.segmenting,
    JobStage.summarizing,
    JobStage.indexing,
]


def _update_job(job_id: uuid.UUID, *, status: JobStatus | None = None, stage: JobStage | None = None, message: str | None = None, extra_meta: Dict[str, Any] | None = None, result_path: str | None = None) -> None:
    session = SessionLocal()
    try:
        job = session.get(Job, job_id)
        if not job:
            return
        if status:
            job.status = status
        if stage:
            job.stage = stage
        meta = job.meta or {}
        progress = meta.get("progress", [])
        if message:
            progress.append({
                "stage": (stage or job.stage).value,
                "message": message,
                "ts": time.time(),
            })
        meta["progress"] = progress
        if extra_meta:
            meta.update(extra_meta)
        job.meta = meta
        if result_path:
            job.result_path = result_path
        session.add(job)
        session.commit()
    finally:
        session.close()


def _write_pdf(output_path: Path, body: str) -> None:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    for line in body.splitlines():
        pdf.multi_cell(0, 10, line)
    pdf.output(output_path)


@celery_app.task(name="pipeline.run", bind=True)
def run_pipeline(self, job_id: str, input_location: str) -> dict:
    job_uuid = uuid.UUID(job_id)
    _update_job(job_uuid, status=JobStatus.running, message="Pipeline started")

    for stage in STAGE_SEQUENCE:
        _update_job(job_uuid, status=JobStatus.running, stage=stage, message=f"{stage.value.replace('_', ' ').title()} complete")
        time.sleep(0.1)

    output_dir = Path(settings.outputs_dir) / job_id
    output_dir.mkdir(parents=True, exist_ok=True)

    notes_md = output_dir / "notes.md"
    notes_text = "# Mock Notes\n\nThese notes were generated by the mocked pipeline for rapid iteration.\n"
    notes_md.write_text(notes_text, encoding="utf-8")

    notes_pdf = output_dir / "notes.pdf"
    _write_pdf(notes_pdf, notes_text)

    flashcards = output_dir / "flashcards.json"
    flashcards.write_text(
        json.dumps(
            [
                {"q": "What is Listenerrr?", "a": "A lecture-to-notes automation service."},
                {"q": "Current stage?", "a": "completed"},
            ],
            indent=2,
        ),
        encoding="utf-8",
    )

    embeddings = output_dir / "search_index.json"
    embeddings.write_text(
        json.dumps(
            {
                "vectors": [[0.1, 0.2, 0.3]],
                "chunks": ["Sample chunk"],
            },
            indent=2,
        ),
        encoding="utf-8",
    )

    artifact_meta = {
        "artifacts": {
            "notes_md": str(notes_md),
            "notes_pdf": str(notes_pdf),
            "flashcards": str(flashcards),
            "search_index": str(embeddings),
        }
    }
    _update_job(
        job_uuid,
        status=JobStatus.finished,
        stage=JobStage.completed,
        message="Job finished",
        extra_meta=artifact_meta,
        result_path=str(output_dir),
    )

    return {"job_id": job_id, "output_dir": str(output_dir), "input": input_location}


__all__ = ["celery_app", "run_pipeline"]
