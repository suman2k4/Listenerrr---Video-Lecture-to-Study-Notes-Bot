{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8733423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcripts/cleaned_transcript.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    transcript_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b26a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"slides_ocr/extracted_slide_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    ocr_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35604385",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\n\", \" \").strip()\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84c95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_transcript = clean_text(transcript_text)\n",
    "clean_ocr = clean_text(ocr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46a95a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_text = f\"Transcription:\\n{clean_transcript}\\n\\nOCR Text from Slides:\\n{clean_ocr}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d11527e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined transcript and OCR text saved at 'combined_text.txt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"combined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_text)\n",
    "\n",
    "print(\"✅ Combined transcript and OCR text saved at 'combined_text.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afc127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a study assistant. Here is the transcription and slide content from a lecture. Extract the main topics, break them into sections with clear headers, and present key points as bullet lists. Also, provide a short summary at the end.\n",
    "\n",
    "Content:\n",
    "{combined_text}\n",
    "\n",
    "Output format:\n",
    "# Section 1: [Header]\n",
    "- Point 1\n",
    "- Point 2\n",
    "\n",
    "# Section 2: [Header]\n",
    "...\n",
    "\n",
    "## Summary:\n",
    "[A short 100-word recap]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ff84c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyChym2onJVHkgLBiXxzFVmOWOcIBwhI6f0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d7a6c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: models/chat-bison-001\n",
      "  - Supported generation methods: ['generateMessage', 'countMessageTokens']\n",
      "\n",
      "Model Name: models/text-bison-001\n",
      "  - Supported generation methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "\n",
      "Model Name: models/embedding-gecko-001\n",
      "  - Supported generation methods: ['embedText', 'countTextTokens']\n",
      "\n",
      "Model Name: models/gemini-1.0-pro-vision-latest\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-pro-vision\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-pro-latest\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-pro-001\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-1.5-pro-002\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-1.5-pro\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-latest\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-001\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-001-tuning\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createTunedModel']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-002\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-8b\n",
      "  - Supported generation methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-8b-001\n",
      "  - Supported generation methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-8b-latest\n",
      "  - Supported generation methods: ['createCachedContent', 'generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0827\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-1.5-flash-8b-exp-0924\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-2.5-pro-exp-03-25\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.5-pro-preview-03-25\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-preview-04-17\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.5-flash-preview-04-17-thinking\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.5-pro-preview-05-06\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-exp\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-001\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-exp-image-generation\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite-001\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-preview-image-generation\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite-preview-02-05\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-lite-preview\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-pro-exp\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-pro-exp-02-05\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-exp-1206\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-01-21\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-thinking-exp-1219\n",
      "  - Supported generation methods: ['generateContent', 'countTokens', 'createCachedContent']\n",
      "\n",
      "Model Name: models/learnlm-1.5-pro-experimental\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/learnlm-2.0-flash-experimental\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemma-3-1b-it\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemma-3-4b-it\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemma-3-12b-it\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/gemma-3-27b-it\n",
      "  - Supported generation methods: ['generateContent', 'countTokens']\n",
      "\n",
      "Model Name: models/embedding-001\n",
      "  - Supported generation methods: ['embedContent']\n",
      "\n",
      "Model Name: models/text-embedding-004\n",
      "  - Supported generation methods: ['embedContent']\n",
      "\n",
      "Model Name: models/gemini-embedding-exp-03-07\n",
      "  - Supported generation methods: ['embedContent', 'countTextTokens']\n",
      "\n",
      "Model Name: models/gemini-embedding-exp\n",
      "  - Supported generation methods: ['embedContent', 'countTextTokens']\n",
      "\n",
      "Model Name: models/aqa\n",
      "  - Supported generation methods: ['generateAnswer']\n",
      "\n",
      "Model Name: models/imagen-3.0-generate-002\n",
      "  - Supported generation methods: ['predict']\n",
      "\n",
      "Model Name: models/gemini-2.0-flash-live-001\n",
      "  - Supported generation methods: ['bidiGenerateContent', 'countTokens']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = genai.list_models()\n",
    "\n",
    "# Print model names and capabilities\n",
    "for model in models:\n",
    "    print(f\"Model Name: {model.name}\")\n",
    "    print(f\"  - Supported generation methods: {model.supported_generation_methods}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "166bdeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a5217fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_text = f\"\"\"\n",
    "Transcription:\n",
    "{clean_transcript}\n",
    "\n",
    "OCR Text from Slides:\n",
    "{clean_ocr}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf9d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = f\"\"\"\n",
    "You are a study assistant. Here is the transcription and slide content from a lecture. Extract the main topics, break them into sections with clear headers, and present key points as bullet lists. Also, provide a short summary at the end.\n",
    "\n",
    "Content:\n",
    "{combined_text}\n",
    "\n",
    "Output format:\n",
    "# Section 1: [Header]\n",
    "- Point 1\n",
    "- Point 2\n",
    "\n",
    "# Section 2: [Header]\n",
    "...\n",
    "\n",
    "## Summary:\n",
    "[A short 100-word recap]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24faa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "385235dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Notes saved to notes/final_notes.md\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generated_notes = response.text.strip()\n",
    "with open(\"notes/final_notes.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(generated_notes)\n",
    "\n",
    "print(\"✅ Notes saved to notes/final_notes.md\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
